{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Salary Estimator: Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created a tool that estimates data science salaries (MAE ~ $ 6K) to help data scientists to negotiate their income when they get a job.  \n",
    "- Scraped over 500 job descriptions from glassdoor using python and selenium  \n",
    "- Cleaned up the data and Data Engineer using pandas data frame \n",
    "- Data engineer on few columns like below\n",
    "- Did Exploratery data analysis with the help of differnet visualization libraries.  \n",
    "- Optimized Linear, Lasso, Ridge and Random Forest Regressors using GridsearchCV to reach the best model.  \n",
    "- Built a client facing API using flask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code and Resources Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python Version**: 3.7  \n",
    "**Packages**: seaborn, pandas, numpy, matplotlib, seaborn, scikit-learn, pickle, flask, json  \n",
    "**For Web Framework Requirements**: pip install -r requirements.txt  \n",
    "**Scraper Github:**:  https://github.com/arapfaik/scraping-glassdoor-selenium  \n",
    "**Scraper Article:**: https://towardsdatascience.com/selenium-tutorial-scraping-glassdoor-com-in-10-minutes-3d0915c6d905  \n",
    "**Flask Productionization:**:https://towardsdatascience.com/productionize-a-machine-learning-model-with-flask-and-heroku-8201260503d2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping\n",
    "\n",
    "Tweaked the web scrapper repo available at above github to get the 500 data science vacancies from glassdoor.com, and after scrapping we fetched below data  \n",
    "\n",
    "* Job title  \n",
    "* Salary Estimate  \n",
    "* Job Description  \n",
    "* Rating  \n",
    "* Company  \n",
    "* Location  \n",
    "* Company Headquarters  \n",
    "* Company Size  \n",
    "* Company Founded Date  \n",
    "* Type of Ownership  \n",
    "* Industry  \n",
    "* Sector  \n",
    "* Revenue  \n",
    "* Competitors  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning  \n",
    "\n",
    "After scraping the data, I needed to clean it up so that it was usable for our model. I made the following changes and created the following variables:\n",
    "\n",
    "* Removed the rows without Salary  \n",
    "* Removing unncessory columns like where we have exception or NULL values  \n",
    "* Parsed the numeric data from columns which was containing alpha numeric values like salary column, Rating column  \n",
    "* Added salary type colum to distinguish the annual and hourly salary  \n",
    "* converted hourly salaries in annual  \n",
    "* Separated location by city and state  \n",
    "* Created company age column from founded year  \n",
    "* Made columns for if different skills were listed in the job description:  \n",
    "    - Python\n",
    "    - R\n",
    "    - Excel\n",
    "    - AWS\n",
    "    - MLE\n",
    "    - Spark\n",
    "    - Data Science  \n",
    "* Column for simplified job title and Seniority  \n",
    "* Column for description length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "I looked at the distributions of the data, coorelation and the value counts for the various categorical and numeric variables. Below are a few highlights.\n",
    "\n",
    "![EDA_Salary_by_Simp](https://raw.githubusercontent.com/rmsharma5989/ds_salary_proj/master/EDA_Salary_by_Simp.png?token=AD2PVLMKHRS66QG4MPMIBEC62JY6E)\n",
    "![EDA_State](https://raw.githubusercontent.com/rmsharma5989/ds_salary_proj/master/EDA_State.png?token=AD2PVLLIFU6EY2OOGKADUUS62JZC6)\n",
    "![EDA_Revenue](https://raw.githubusercontent.com/rmsharma5989/ds_salary_proj/master/EDA_Revenue.png?token=AD2PVLPWQX5YBNATW26SZVS62JZFU)\n",
    "Word cloud for salary description column  \n",
    "![EDA_wordcloud](https://raw.githubusercontent.com/rmsharma5989/ds_salary_proj/master/EDA_wordcloud.png?token=AD2PVLPZDLOC6GEDEITZBLS62JZJQ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "First, I transformed the categorical variables into dummy variables. I also split the data into train and tests sets with a test size of 20%.  \n",
    "\n",
    "I tried four different models and evaluated them using Mean Absolute Error. I chose MAE because it is relatively easy to interpret and outliers arenâ€™t particularly bad in for this type of model.  \n",
    "\n",
    "I tried four different models:\n",
    "*  **Multiple Linear Regression**: Baseline for the model\n",
    "* **Lasso Regression**: Because of the sparse data from the many categorical variables, I thought a normalized regression like lasso would be effective.  \n",
    "* **Ridge Regression**: Becasue of sparse data i wanted to check if Ridge performs bette than Lasso and i for little improvement with Ridhe.  \n",
    "* **Random Forest**: Again, with the sparsity associated with the data, I thought that this would be a good fit.\n",
    "\n",
    "## Model Performance  \n",
    "* **Multiple Linear Regression**: MAE = 13.72  \n",
    "* **Lasso Regression**: MAE = 7.29  \n",
    "* **Ridge Regression**: MAE = 7.12  \n",
    "* **Random Forest**: MAE = 6.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
